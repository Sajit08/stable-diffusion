{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About Notebook\n\nIt is basic starter notebook for Stable-Diffusion Image-to-Prompt, written in `keras`, `keras-cv`, and `transformer` from huggingface. It contains both **training code** and **inference code**. Please note, the training code is configured on **TPU-VM**, otherwise on **GPU**.\n","metadata":{}},{"cell_type":"code","source":"# set True for 'Inference' on GPU (turn off the internet)\n# set False for 'Training' on TPU-VM (turn on the internet)\nSUBMIT = False","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:02:43.666521Z","iopub.execute_input":"2023-04-22T05:02:43.667416Z","iopub.status.idle":"2023-04-22T05:02:43.681960Z","shell.execute_reply.started":"2023-04-22T05:02:43.667368Z","shell.execute_reply":"2023-04-22T05:02:43.681153Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nimport logging\nfrom IPython.display import clear_output\nwarnings.filterwarnings('ignore')\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nlogging.disable(logging.WARNING)\n\n\nif SUBMIT:\n    !pip install --no-deps ../input/keras-cv/keras_cv-0.4.2-py3-none-any.whl\nelse:\n    !pip install -U -q scikit-learn\n    !pip install -U -q transformers\n    \nclear_output()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:02:44.774862Z","iopub.execute_input":"2023-04-22T05:02:44.775629Z","iopub.status.idle":"2023-04-22T05:03:06.437738Z","shell.execute_reply.started":"2023-04-22T05:02:44.775594Z","shell.execute_reply":"2023-04-22T05:03:06.436940Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd \nimport warnings\nimport random\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.optimizers import schedules\nfrom tensorflow.python.client import device_lib\n\ntry:\n    import keras_cv\n    from keras_cv.layers import RandomBrightness\n    from keras_cv.layers import RandomChannelShift\n    from keras_cv.layers import RandomFlip\nexcept:\n    from keras.layers import RandomFlip\n\nimport transformers\nfrom transformers import AutoConfig\nfrom transformers import TFBertTokenizer\nfrom transformers import TFAutoModel\nfrom transformers import ViTFeatureExtractor\nfrom transformers import TFViTModel\n\ntransformers.logging.disable_progress_bar()\nclear_output()","metadata":{"papermill":{"duration":11.202741,"end_time":"2023-03-18T22:39:34.823950","exception":false,"start_time":"2023-03-18T22:39:23.621209","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:03:06.439702Z","iopub.execute_input":"2023-04-22T05:03:06.439930Z","iopub.status.idle":"2023-04-22T05:04:07.928176Z","shell.execute_reply.started":"2023-04-22T05:03:06.439901Z","shell.execute_reply":"2023-04-22T05:04:07.927250Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Devices","metadata":{"papermill":{"duration":0.004167,"end_time":"2023-03-18T22:39:34.832573","exception":false,"start_time":"2023-03-18T22:39:34.828406","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if SUBMIT:\n    physical_devices = tf.config.list_physical_devices('GPU')\n    tf.config.optimizer.set_jit(True)\n    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n    [tf.config.experimental.set_memory_growth(pd, True) for pd in physical_devices]\n    strategy = tf.distribute.MirroredStrategy()\nelse:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\")\n    strategy = tf.distribute.TPUStrategy(tpu)\n    keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n\n    \nseed = 42\ninput_size = 224\nbatch_size = 32 * strategy.num_replicas_in_sync\nnum_epochs = 10\nkeras.utils.set_random_seed(seed)\ntf.__version__, transformers.__version__","metadata":{"papermill":{"duration":6.409012,"end_time":"2023-03-18T22:39:41.245804","exception":false,"start_time":"2023-03-18T22:39:34.836792","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:04:07.929931Z","iopub.execute_input":"2023-04-22T05:04:07.930141Z","iopub.status.idle":"2023-04-22T05:04:17.129095Z","shell.execute_reply.started":"2023-04-22T05:04:07.930115Z","shell.execute_reply":"2023-04-22T05:04:17.128234Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('2.12.0', '4.28.1')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data [Training]","metadata":{"papermill":{"duration":0.004066,"end_time":"2023-03-18T22:39:41.254555","exception":false,"start_time":"2023-03-18T22:39:41.250489","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diffusiondb-data-cleansing/diffusiondb.csv')\ntrn_df, val_df = train_test_split(\n    df, test_size=0.1, random_state=seed\n)\ntrn_df.shape, val_df.shape","metadata":{"papermill":{"duration":0.697233,"end_time":"2023-03-18T22:39:41.956087","exception":false,"start_time":"2023-03-18T22:39:41.258854","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:03.001727Z","iopub.execute_input":"2023-04-22T05:05:03.002002Z","iopub.status.idle":"2023-04-22T05:05:03.776487Z","shell.execute_reply.started":"2023-04-22T05:05:03.001973Z","shell.execute_reply":"2023-04-22T05:05:03.775453Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((138888, 2), (15432, 2))"},"metadata":{}}]},{"cell_type":"code","source":"# get max sequence\ntrn_df[\"prompt\"].apply(lambda x: len(x.split())).describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:05:04.871561Z","iopub.execute_input":"2023-04-22T05:05:04.871868Z","iopub.status.idle":"2023-04-22T05:05:05.146496Z","shell.execute_reply.started":"2023-04-22T05:05:04.871836Z","shell.execute_reply":"2023-04-22T05:05:05.145349Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"count    138888.000000\nmean         13.130083\nstd          10.864133\nmin           5.000000\n25%           7.000000\n50%          10.000000\n75%          15.000000\nmax         480.000000\nName: prompt, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dataloader [Training]","metadata":{"papermill":{"duration":0.004263,"end_time":"2023-03-18T22:39:41.965431","exception":false,"start_time":"2023-03-18T22:39:41.961168","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_id = 'sentence-transformers/all-MiniLM-L6-v2'\ntokenizer = TFBertTokenizer.from_pretrained(model_id)\n\ndef read_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_png(image, 3)\n    image = tf.image.resize(image, (input_size, input_size))\n    return image\n\ndef batch_tokenize(prompt):\n    tokenized = tokenizer(\n        prompt, \n        padding=\"max_length\", \n        truncation=True, \n        max_length=128\n    )\n    return tokenized","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:05:07.997128Z","iopub.execute_input":"2023-04-22T05:05:07.997438Z","iopub.status.idle":"2023-04-22T05:05:10.009283Z","shell.execute_reply.started":"2023-04-22T05:05:07.997405Z","shell.execute_reply":"2023-04-22T05:05:10.008286Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def dataloader(\n    image_paths, \n    prompts, \n    shuffle=True, \n    repeat=True, \n    batch_size=1,\n):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, prompts))\n    dataset = dataset.map(\n        lambda x, y: (read_image(x), y),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    dataset = dataset.batch(\n        batch_size, drop_remainder=True\n    )\n\n    dataset = dataset.map(\n        lambda x, y: (x, (batch_tokenize(y))),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    if shuffle:\n        dataset = dataset.shuffle(\n            batch_size * 8, reshuffle_each_iteration = False\n        )\n    \n    if repeat:\n        dataset = dataset.repeat()\n        \n    return dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"papermill":{"duration":0.015733,"end_time":"2023-03-18T22:39:41.985631","exception":false,"start_time":"2023-03-18T22:39:41.969898","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:10.897861Z","iopub.execute_input":"2023-04-22T05:05:10.898716Z","iopub.status.idle":"2023-04-22T05:05:10.907573Z","shell.execute_reply.started":"2023-04-22T05:05:10.898667Z","shell.execute_reply":"2023-04-22T05:05:10.906619Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_ds = dataloader(\n    trn_df[\"filepath\"].values, \n    trn_df['prompt'].values, \n    shuffle=True, \n    repeat=False,\n    batch_size=batch_size\n)\n\nvalid_ds = dataloader(\n    val_df[\"filepath\"].values, \n    val_df['prompt'].values, \n    shuffle=False, \n    repeat=False, \n    batch_size=batch_size\n)","metadata":{"papermill":{"duration":0.202647,"end_time":"2023-03-18T22:39:42.192644","exception":false,"start_time":"2023-03-18T22:39:41.989997","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:13.250451Z","iopub.execute_input":"2023-04-22T05:05:13.250776Z","iopub.status.idle":"2023-04-22T05:05:16.499613Z","shell.execute_reply.started":"2023-04-22T05:05:13.250742Z","shell.execute_reply":"2023-04-22T05:05:16.498476Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-03-17T18:01:43.721927Z","iopub.status.busy":"2023-03-17T18:01:43.721406Z","iopub.status.idle":"2023-03-17T18:01:43.728693Z","shell.execute_reply":"2023-03-17T18:01:43.727048Z","shell.execute_reply.started":"2023-03-17T18:01:43.721886Z"},"papermill":{"duration":0.00467,"end_time":"2023-03-18T22:39:42.202125","exception":false,"start_time":"2023-03-18T22:39:42.197455","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def preprocess(x):\n    x = keras.layers.Rescaling(scale=1./127.5, offset=-1.0)(x)\n    x = keras.layers.Permute(dims=(3, 1, 2))(x)\n    return x\n    \ndef augment(x):\n    try:\n        pipeline = keras_cv.layers.RandomChoice(\n            layers=[\n                RandomFlip(\"horizontal\")\n            ],\n            auto_vectorize=True\n        )\n    except:\n        pipeline = keras.Sequential(\n            [\n                keras.layers.RandomFlip(\"horizontal\")\n            ]\n        )\n    return pipeline(x)","metadata":{"papermill":{"duration":0.013431,"end_time":"2023-03-18T22:39:42.219958","exception":false,"start_time":"2023-03-18T22:39:42.206527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:24.309244Z","iopub.execute_input":"2023-04-22T05:05:24.309546Z","iopub.status.idle":"2023-04-22T05:05:24.317817Z","shell.execute_reply.started":"2023-04-22T05:05:24.309514Z","shell.execute_reply":"2023-04-22T05:05:24.316757Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_model(mode='inference'):\n    input = keras.Input(shape=(input_size, input_size, 3))\n    x = augment(input)\n    x = preprocess(x)\n\n    # vit model\n    if mode=='inference':\n        config =  AutoConfig.from_pretrained(\n            '/kaggle/input/cmp-stablediffusion-imgtopt', \n            local_files_only=True\n        )\n        hf_model = TFViTModel.from_config(config)\n        x = hf_model(x)\n    else:\n        x = TFViTModel.from_pretrained(\n            'google/vit-base-patch16-224'\n        )(x)\n    x = keras.layers.Lambda(lambda v: v[:, 0])(x.last_hidden_state)\n    \n    # output\n    output = keras.layers.Dense(\n        384, activation=None, dtype=tf.float32\n    )(x)\n\n    model = keras.Model(input, output)\n    return model","metadata":{"papermill":{"duration":0.013599,"end_time":"2023-03-18T22:39:42.238042","exception":false,"start_time":"2023-03-18T22:39:42.224443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:27.599910Z","iopub.execute_input":"2023-04-22T05:05:27.600735Z","iopub.status.idle":"2023-04-22T05:05:27.608980Z","shell.execute_reply.started":"2023-04-22T05:05:27.600694Z","shell.execute_reply":"2023-04-22T05:05:27.608175Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Sentence Transformer (all-MiniLM-L6-v2)**\n\nIt will be run on inside the model.","metadata":{"papermill":{"duration":0.004217,"end_time":"2023-03-18T22:39:42.246935","exception":false,"start_time":"2023-03-18T22:39:42.242718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ref. https://www.philschmid.de/tensorflow-sentence-transformers\nclass TFSentenceTransformer(keras.layers.Layer):\n    def __init__(self,  model_id, **kwargs):\n        super().__init__(**kwargs)\n        self.st_model = TFAutoModel.from_pretrained(model_id, **kwargs)\n\n    def call(self, inputs, normalize=True):\n        model_output = self.st_model(inputs)\n        embeddings = self.mean_pooling(\n            model_output, inputs[\"attention_mask\"]\n        )\n        if normalize:\n            embeddings = self.normalize(embeddings)\n        return embeddings\n\n    def mean_pooling(self, model_output, attention_mask):\n        token_embeddings = model_output[0]\n        input_mask_expanded = tf.cast(\n            tf.broadcast_to(\n                tf.expand_dims(attention_mask, -1), \n                tf.shape(token_embeddings)\n            ),\n            token_embeddings.dtype\n        )\n        token_mask = tf.reduce_sum(\n            token_embeddings * input_mask_expanded, axis=1\n        )\n        mask_clip = tf.clip_by_value(\n            tf.reduce_sum(input_mask_expanded, axis=1), \n            1e-9, \n            tf.float32.max\n        )\n        return token_mask / mask_clip\n        \n    def normalize(self, embeddings):\n        embeddings, _ = tf.linalg.normalize(\n            embeddings, 2, axis=1\n        )\n        return embeddings","metadata":{"papermill":{"duration":0.016905,"end_time":"2023-03-18T22:39:42.268476","exception":false,"start_time":"2023-03-18T22:39:42.251571","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:30.534120Z","iopub.execute_input":"2023-04-22T05:05:30.534993Z","iopub.status.idle":"2023-04-22T05:05:30.546025Z","shell.execute_reply.started":"2023-04-22T05:05:30.534950Z","shell.execute_reply":"2023-04-22T05:05:30.544784Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TextTokenToEmbedding(keras.Model):\n    '''Transform the text/prompt-token gt to 384-D embedding with sentence transformer.\n    '''\n    def __init__(self, model, **kwargs):\n        super().__init__(**kwargs)\n        self.model = model \n    \n    def call(self, inputs):\n        return self.model(inputs)\n    \n    def train_step(self, data):\n        x, y = data\n        y = tfst_model(y, normalize=False)\n        return super().train_step((x, y))\n    \n    def test_step(self, data):\n        x, y = data\n        y = tfst_model(y, normalize=False)\n        return super().test_step((x, y))\n    \n    # kaggle.com/code/ipythonx/keras-rsna-breast-cancer-detection\n    def save_weights(\n        self, filepath, overwrite=True, save_format=None, options=None\n    ):\n        # Overriding this method will allow us to use the `ModelCheckpoint`\n        self.model.save_weights(\n            filepath=filepath,\n            overwrite=overwrite,\n            save_format=save_format,\n            options=options,\n        )\n        \n    def save(\n        self, filepath, overwrite=True, include_optimizer=True, \n        save_format=None, signatures=None, options=None\n    ):\n        # Overriding this method will allow us to use the `ModelCheckpoint`\n        self.model.save(\n            filepath=filepath,\n            overwrite=overwrite,\n            save_format=save_format,\n            options=options,\n            include_optimizer=include_optimizer,\n            signatures=signatures\n        )","metadata":{"papermill":{"duration":0.017489,"end_time":"2023-03-18T22:39:42.290472","exception":false,"start_time":"2023-03-18T22:39:42.272983","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:33.295220Z","iopub.execute_input":"2023-04-22T05:05:33.295512Z","iopub.status.idle":"2023-04-22T05:05:33.307888Z","shell.execute_reply.started":"2023-04-22T05:05:33.295480Z","shell.execute_reply":"2023-04-22T05:05:33.306894Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# https://stackoverflow.com/a/44933346/9215780\ncosine_similarity_loss = keras.losses.CosineSimilarity(\n    reduction='none'\n)\n\ndef CosineEmbeddingLoss(margin=0., target=1):\n    def cosine_embedding_loss_fn(input_one, input_two):\n        similarity = - cosine_similarity_loss(input_one, input_two)\n        return tf.reduce_mean(\n            tf.where(\n                tf.equal(target, 1),\n                1. - similarity,\n                tf.maximum(\n                    tf.zeros_like(similarity), similarity - margin\n                )\n            )\n        )\n    return cosine_embedding_loss_fn","metadata":{"papermill":{"duration":0.014447,"end_time":"2023-03-18T22:39:42.309438","exception":false,"start_time":"2023-03-18T22:39:42.294991","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:05:35.971482Z","iopub.execute_input":"2023-04-22T05:05:35.972198Z","iopub.status.idle":"2023-04-22T05:05:35.979687Z","shell.execute_reply.started":"2023-04-22T05:05:35.972156Z","shell.execute_reply":"2023-04-22T05:05:35.978784Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\nwith strategy.scope():\n    if SUBMIT:\n        model = get_model(mode='inference')\n        model.load_weights(\n            '/kaggle/input/cmp-stablediffusion-imgtopt/model.02-0.533.h5'\n        )\n        model.compile(jit_compile=True)\n        model.trainable = False\n    else:\n        # token to text-embedding\n        tfst_model = TFSentenceTransformer(model_id)\n        tfst_model.trainable = False\n\n        model = get_model(mode='training')\n        model = TextTokenToEmbedding(model)\n        \n        BASE_LR = 0.005 * batch_size / 16\n        lr_decay = keras.optimizers.schedules.PiecewiseConstantDecay(\n            boundaries=[12000 * 16, 16000 * 16],\n            values=[BASE_LR, 0.1 * BASE_LR, 0.01 * BASE_LR],\n        )\n        optim = keras.optimizers.SGD(\n            learning_rate=lr_decay, momentum=0.9, global_clipnorm=10.0\n        )\n\n        model.compile(\n            optimizer=optim,\n            loss=CosineEmbeddingLoss(margin=0., target=1),\n            metrics=[\n                metrics.CosineSimilarity(name='cos')\n            ],\n        )\n        model.build(\n            input_shape=(None, input_size, input_size, 3)\n        )\n    \nclear_output()","metadata":{"papermill":{"duration":25.308905,"end_time":"2023-03-18T22:40:07.632154","exception":false,"start_time":"2023-03-18T22:39:42.323249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:06:15.096571Z","iopub.execute_input":"2023-04-22T05:06:15.096903Z","iopub.status.idle":"2023-04-22T05:06:53.972947Z","shell.execute_reply.started":"2023-04-22T05:06:15.096868Z","shell.execute_reply":"2023-04-22T05:06:53.972047Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.summary(\n    expand_nested=True, \n    line_length=100, \n    show_trainable=True\n)","metadata":{"papermill":{"duration":0.108371,"end_time":"2023-03-18T22:40:07.746667","exception":false,"start_time":"2023-03-18T22:40:07.638296","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:06:53.974502Z","iopub.execute_input":"2023-04-22T05:06:53.974714Z","iopub.status.idle":"2023-04-22T05:06:54.039909Z","shell.execute_reply.started":"2023-04-22T05:06:53.974688Z","shell.execute_reply":"2023-04-22T05:06:54.038966Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"text_token_to_embedding\"\n_______________________________________________________________________________________________________________\n Layer (type)                                Output Shape                            Param #        Trainable  \n===============================================================================================================\n model (Functional)                          (None, 384)                             86684544       Y          \n|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n| input_1 (InputLayer)                      [(None, 224, 224, 3)]                   0              Y          |\n|                                                                                                             |\n| sequential (Sequential)                   (None, 224, 224, 3)                     0              Y          |\n||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n|| random_flip (RandomFlip)                (None, 224, 224, 3)                     0              Y          ||\n|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n| rescaling (Rescaling)                     (None, 224, 224, 3)                     0              Y          |\n|                                                                                                             |\n| permute (Permute)                         (None, 3, 224, 224)                     0              Y          |\n|                                                                                                             |\n| tf_vi_t_model (TFViTModel)                TFBaseModelOutputWithPooling(last_hidd  86389248       Y          |\n|                                           en_state=(None, 197, 768),                                        |\n|                                            pooler_output=(None, 768),                                       |\n|                                            hidden_states=None, attentions=None)                             |\n||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n|| vit (TFViTMainLayer)                    multiple                                86389248       Y          ||\n|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n| lambda (Lambda)                           (None, 768)                             0              Y          |\n|                                                                                                             |\n| dense (Dense)                             (None, 384)                             295296         Y          |\n¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n===============================================================================================================\nTotal params: 86,684,544\nTrainable params: 86,684,544\nNon-trainable params: 0\n_______________________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"if SUBMIT:\n    training_log = pd.read_csv('/kaggle/input/cmp-stablediffusion-imgtopt/training_log.csv')\n    display(training_log.head())\nelse:\n    model.fit(\n        train_ds, \n        validation_data=valid_ds, \n        epochs=num_epochs,\n        callbacks=[\n            callbacks.ModelCheckpoint(\n                filepath='model.{epoch:02d}-{val_cos:.3f}.h5',\n                monitor='val_cos',\n                mode='max',\n                save_best_only=True\n            ),\n            callbacks.CSVLogger('training_log.csv')\n        ]\n    )","metadata":{"papermill":{"duration":20111.777777,"end_time":"2023-03-19T04:15:19.532497","exception":false,"start_time":"2023-03-18T22:40:07.754720","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:11:04.461819Z","iopub.execute_input":"2023-04-22T05:11:04.462158Z","iopub.status.idle":"2023-04-22T05:39:26.159774Z","shell.execute_reply.started":"2023-04-22T05:11:04.462121Z","shell.execute_reply":"2023-04-22T05:39:26.158445Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n542/542 [==============================] - 330s 271ms/step - loss: 0.5968 - cos: 0.4032 - val_loss: 0.5519 - val_cos: 0.4481\nEpoch 2/10\n542/542 [==============================] - 152s 228ms/step - loss: 0.5335 - cos: 0.4665 - val_loss: 0.5251 - val_cos: 0.4749\nEpoch 3/10\n542/542 [==============================] - 152s 228ms/step - loss: 0.5135 - cos: 0.4865 - val_loss: 0.5111 - val_cos: 0.4889\nEpoch 4/10\n542/542 [==============================] - 152s 228ms/step - loss: 0.5009 - cos: 0.4991 - val_loss: 0.5017 - val_cos: 0.4983\nEpoch 5/10\n542/542 [==============================] - 151s 228ms/step - loss: 0.4915 - cos: 0.5085 - val_loss: 0.4947 - val_cos: 0.5053\nEpoch 6/10\n542/542 [==============================] - 152s 229ms/step - loss: 0.4840 - cos: 0.5160 - val_loss: 0.4894 - val_cos: 0.5106\nEpoch 7/10\n542/542 [==============================] - 151s 227ms/step - loss: 0.4776 - cos: 0.5224 - val_loss: 0.4849 - val_cos: 0.5151\nEpoch 8/10\n542/542 [==============================] - 152s 229ms/step - loss: 0.4719 - cos: 0.5281 - val_loss: 0.4812 - val_cos: 0.5188\nEpoch 9/10\n542/542 [==============================] - 151s 227ms/step - loss: 0.4668 - cos: 0.5332 - val_loss: 0.4782 - val_cos: 0.5218\nEpoch 10/10\n542/542 [==============================] - 151s 226ms/step - loss: 0.4621 - cos: 0.5379 - val_loss: 0.4757 - val_cos: 0.5243\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data [Inference]","metadata":{}},{"cell_type":"code","source":"comp_path = '/kaggle/input/stable-diffusion-image-to-prompts'\nimag_path = glob.glob(f'{comp_path}/images/*.png')\nimages = os.listdir(os.path.join(comp_path, 'images'))\nimgIds = [i.split('.')[0] for i in images]\n\nEMBEDDING_LENGTH = 384\neIds = list(range(EMBEDDING_LENGTH))\n\nimgId_eId = [\n    '_'.join(map(str, i)) for i in zip(\n        np.repeat(imgIds, EMBEDDING_LENGTH),\n        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))\n]","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-22T05:41:07.326263Z","iopub.execute_input":"2023-04-22T05:41:07.326555Z","iopub.status.idle":"2023-04-22T05:41:07.348174Z","shell.execute_reply.started":"2023-04-22T05:41:07.326525Z","shell.execute_reply":"2023-04-22T05:41:07.346944Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader [Inference]","metadata":{}},{"cell_type":"code","source":"def dataloader(\n    image_paths, batch_size=1\n):\n    dataset = tf.data.Dataset.from_tensor_slices(\n        (image_paths)\n    )\n    dataset = dataset.map(read_image, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    return dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:41:10.457258Z","iopub.execute_input":"2023-04-22T05:41:10.457547Z","iopub.status.idle":"2023-04-22T05:41:10.464389Z","shell.execute_reply.started":"2023-04-22T05:41:10.457518Z","shell.execute_reply":"2023-04-22T05:41:10.463147Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_ds = dataloader(\n    imag_path, batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:41:11.378145Z","iopub.execute_input":"2023-04-22T05:41:11.378442Z","iopub.status.idle":"2023-04-22T05:41:11.408636Z","shell.execute_reply.started":"2023-04-22T05:41:11.378412Z","shell.execute_reply":"2023-04-22T05:41:11.407377Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"prompt_embeddings = model.predict(test_ds)\nprompt_embeddings = np.vstack(prompt_embeddings).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:41:14.513030Z","iopub.execute_input":"2023-04-22T05:41:14.513366Z","iopub.status.idle":"2023-04-22T05:41:28.126010Z","shell.execute_reply.started":"2023-04-22T05:41:14.513330Z","shell.execute_reply":"2023-04-22T05:41:28.124583Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 14s 14s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(\n    index=imgId_eId,\n    data=prompt_embeddings,\n    columns=['val']\n).rename_axis('imgId_eId')\nsubmission.to_csv('submission.csv')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T05:41:28.128050Z","iopub.execute_input":"2023-04-22T05:41:28.128604Z","iopub.status.idle":"2023-04-22T05:41:28.151399Z","shell.execute_reply.started":"2023-04-22T05:41:28.128567Z","shell.execute_reply":"2023-04-22T05:41:28.150337Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                  val\nimgId_eId            \nf27825b2c_0 -0.572822\nf27825b2c_1  0.877553\nf27825b2c_2 -0.585785\nf27825b2c_3  0.817140\nf27825b2c_4 -0.840025","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>val</th>\n    </tr>\n    <tr>\n      <th>imgId_eId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f27825b2c_0</th>\n      <td>-0.572822</td>\n    </tr>\n    <tr>\n      <th>f27825b2c_1</th>\n      <td>0.877553</td>\n    </tr>\n    <tr>\n      <th>f27825b2c_2</th>\n      <td>-0.585785</td>\n    </tr>\n    <tr>\n      <th>f27825b2c_3</th>\n      <td>0.817140</td>\n    </tr>\n    <tr>\n      <th>f27825b2c_4</th>\n      <td>-0.840025</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}